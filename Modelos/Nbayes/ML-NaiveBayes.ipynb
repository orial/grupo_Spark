{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En Python existen múltiples formas de aplicar machine learning para el reconocimiento de patrones. Una de estas consiste en los clasificadores probabilísticos, entre los cuales encontramos el __teorema de Bayes.__\n",
    "\n",
    "Bayes se caracteriza por asumir una gran independencia entre las características que se encuentran en los datos, lo cual ofrece una perspectiva distinta de el problema que se va a resolver: Obtener la categoría del crimen dada su localización en distrito, hora, día de la semana y mes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías\n",
    "\n",
    "Se utilizará pandas y sklearn para poder utilizar los dataframes y modelos necesarios. Pprint para visualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuperación y formato de datos\n",
    "\n",
    "En primer lugar obtenemos el CSV en partes. Se realizará un filtrado de fechas y tiempo (hora) para poder trabajar con los datos. Las dos partes se obtienen para separar un conjunto de entrenamiento, y otro de testeo, que hará de entrada simulada en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://storage.googleapis.com/grupospark/incidents.all.ordered.date.csv'\n",
    "test = pd.read_csv(url, parse_dates=['Date'], header=0, nrows=10000)\n",
    "test['Time'] = pd.to_datetime(test['Time'],format='%H:%M')\n",
    "train = pd.read_csv(url, parse_dates=['Date'],  header=0,skiprows=range(1,10000),nrows=90000)\n",
    "train['Time'] = pd.to_datetime(train['Time'],format='%H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y tests\n",
    "\n",
    "Bayes es una técnica cuya clasificación puede ser entrenada de forma muy eficiente siempre que sea de forma __supervisada__, es por ello que se normalizarán los datos para entrenarlos o procesarlos. Se realiza un pre-procesamiento con las siguientes funciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data): # Normalización de características.\n",
    "    data = (data - data.mean()) / (data.max() - data.min())\n",
    "    return data\n",
    "\n",
    "# Preparación de datos\n",
    "def prep_data(data, test):\n",
    "    if (test == 0):\n",
    "        # Se realiza una codificación de las etiquetas\n",
    "        crimen_labels = preprocessing.LabelEncoder()\n",
    "        crimen_encode = crimen_labels.fit_transform(data.Category)\n",
    "\n",
    "    # Con get_dummies convertimos nuestros valores categóricos en valores númericos con los que poder trabajar\n",
    "    days = pd.get_dummies(data.DayOfWeek)\n",
    "    district = pd.get_dummies(data.PdDistrict)\n",
    "    month = pd.get_dummies(data.Date.dt.month,prefix=\"m\")\n",
    "    hour = data.Time.dt.hour\n",
    "    hour = pd.get_dummies(hour)\n",
    "\n",
    "    # Construimos el array a partir de los datos obtenidos\n",
    "    prepared_data = pd.concat([hour, month, days, district], axis=1)\n",
    "    prepared_data['X'] = normalize(data.X)\n",
    "    prepared_data['Y'] = normalize(data.Y)\n",
    "\n",
    "    if (test == 0):\n",
    "        prepared_data['crime'] = crimen_encode\n",
    "\n",
    "    return prepared_data\n",
    "\n",
    "# Preprocesamiento llevado a cabo\n",
    "train_proc = prep_data(train, 0)\n",
    "test_proc = prep_data(test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Características a utilizar\n",
    "\n",
    "Es esencial, en este algoritmo, especificar qué valores obtenidos desde la fuente de datos queremos utilizar como punto de partida para la clasificación. En la función anterior distinguimos los meses (con prefijo \"m_\") de las horas (el rango numérico de 0 a 23). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [  'm_1', 'm_2', 'm_3', 'm_4', 'm_5', 'm_6', 'm_7', 'm_8', 'm_9', 'm_10', 'm_11', 'm_12',\n",
    "               'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday',\n",
    "               'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN',\n",
    "               'TARAVAL', 'TENDERLOIN'\n",
    "           ] + [x for x in range(0, 24)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes y predicciones\n",
    "\n",
    "Con el modelo de Bernoulli, que equivale al modelo binario de independencia, realizamos nuestro modelo a partir del conjunto de entrenamiento ya preparado. Tras esto, con el mismo modelo intentamos predecir los casos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(train_proc[features], train_proc['crime'])\n",
    "predicted = model.predict_proba(test_proc[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados y análisis\n",
    "\n",
    "Por último, exponemos el resultado de nuestro proceso. Dado que estamos en el repositorio, comentado el código para almacenar este en un CSV. En su lugar convertimos este a un listado de diccionarios sobre el que podemos iterar para obtener los tres primeros casos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARSON': 0.034332225834823565,\n 'ASSAULT': 0.047551791152962736,\n 'BAD CHECKS': 0.0028829952318701405,\n 'BRIBERY': 0.013526986958289225,\n 'BURGLARY': 0.02731243879623048,\n 'DISORDERLY CONDUCT': 0.004351904024434736,\n 'DRIVING UNDER THE INFLUENCE': 0.005169667320699265,\n 'DRUG/NARCOTIC': 0.0993090885750867,\n 'DRUNKENNESS': 0.0019527956268837066,\n 'EMBEZZLEMENT': 0.012016693387333568,\n 'EXTORTION': 0.0017078669536744534,\n 'FAMILY OFFENSES': 0.0036255612759995286,\n 'FORGERY/COUNTERFEITING': 0.026312768999884172,\n 'FRAUD': 0.01038061964305988,\n 'GAMBLING': 0.0070507821226408985,\n 'KIDNAPPING': 0.012860688585998665,\n 'LARCENY/THEFT': 0.022770216117140567,\n 'LIQUOR LAWS': 0.005433796665775091,\n 'LOITERING': 0.014457488665450862,\n 'MISSING PERSON': 0.021583838781292233,\n 'NON-CRIMINAL': 0.028694929727619296,\n 'OTHER OFFENSES': 0.12787248134197488,\n 'PORNOGRAPHY/OBSCENE MAT': 4.1608133663723245e-07,\n 'PROSTITUTION': 5.20058065245541e-05,\n 'ROBBERY': 0.012147180452482009,\n 'RUNAWAY': 0.004559475780457875,\n 'SECONDARY CODES': 0.02734717537657905,\n 'SEX OFFENSES, FORCIBLE': 0.020067755958067337,\n 'SEX OFFENSES, NON FORCIBLE': 0.0018692613871580982,\n 'STOLEN PROPERTY': 0.005564584733291485,\n 'SUICIDE': 0.005869059564852941,\n 'SUSPICIOUS OCC': 0.011698214336841362,\n 'TRESPASS': 0.004828874844694987,\n 'VANDALISM': 0.018721245613633475,\n 'VEHICLE THEFT': 0.011754759272107455,\n 'WARRANTS': 0.3044903283572655,\n 'WEAPON LAWS': 0.03987203664558263}\n\n\nCaso 0 : Categoría->  WARRANTS | Resultado->  0.3044903283572655\nCaso 1 : Categoría->  WARRANTS | Resultado->  0.17823174563083816\nCaso 2 : Categoría->  LARCENY/THEFT | Resultado->  0.19658437070412366\n"
     ]
    }
   ],
   "source": [
    "# Write results\n",
    "crimen_labels = preprocessing.LabelEncoder()\n",
    "crimen = crimen_labels.fit_transform(train.Category)\n",
    "result = pd.DataFrame(predicted, columns=crimen_labels.classes_)\n",
    "#result.to_csv('results.csv', index=True, index_label='Id'\n",
    "\n",
    "result_dict = result.to_dict(orient='records')\n",
    "\n",
    "# Primer caso de test, para visualizar la estructura\n",
    "pprint.pprint(result_dict[0])\n",
    "print('\\n')\n",
    "# Iteramos sobre los tres primeros tests, para visualizar cuál es el valor máximo de cada resultado\n",
    "for i, row in enumerate(result_dict):\n",
    "    maximo = max(row, key=lambda key: row[key])\n",
    "    print('Caso',i,': Categoría-> ',maximo, '| Resultado-> ',row[maximo])\n",
    "    if i == 2:\n",
    "        break;\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Podemos observar que el objeto resultado es un diccinario de todas las posibles categorías de crímenes con sus respectivas probabilidades.\n",
    "\n",
    "En los tres primeros casos de ejemplo, tenemos un __30%__ de probabilidad de que sea __WARRANTS__, en el segundo, un __17%__, y en el tercero, un __19%__ de que sea un robo. \n",
    "\n",
    "El procesamiento por Bayes no es del todo certero, pero sí veloz gracias a su forma de procesar las categorías, siendo un buen candidato para este tipo de predicciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
