{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy\n",
    "import numpy\n",
    "import matplotlib\n",
    "import pandas\n",
    "import sklearn\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos con todos los incidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"/Users/vrandkode/Workspace/M2/CienciaDeDatosII/datasets/incidents.all.ml.csv\"\n",
    "names = ['category', 'type', 'dayofweek', 'date', 'time','day','year','month','hour','district', 'resolution', 'latitude', 'longitude']\n",
    "dataset = pandas.read_csv(url, names=names, sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de clasificación\n",
    "* Random forests\n",
    "* Neural networks\n",
    "* Klustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con ayuda de una red neuronal en Python intentaremos averigüar si dada un distrito y dia de la semana hay posibilidades de producirse un tipo de delito o no. Usaremos el conjunto de datos de incidentes del Repositorio de aprendizaje automático de UCI. Intentaremos construir un modelo que pueda clasificar en función de las situaciones: distrito, dia de la semana  e intentar predecir el tipo de delito que pueda producirse por la zona utilizando redes neuronales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Descarte de las columnas para realizar una mejor discretación de los atributos para realizar la clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                 category  dayofweek        date    district      resolution\n",
       "0           NON-CRIMINAL     Monday  2015-01-19     MISSION            NONE\n",
       "1                ROBBERY     Sunday  2015-02-01  TENDERLOIN            NONE\n",
       "2                ASSAULT     Sunday  2015-02-01  TENDERLOIN            NONE\n",
       "3        SECONDARY CODES     Sunday  2015-02-01  TENDERLOIN            NONE\n",
       "4              VANDALISM    Tuesday  2015-01-27    NORTHERN            NONE\n",
       "5           NON-CRIMINAL     Sunday  2015-02-01    RICHMOND            NONE\n",
       "6        SECONDARY CODES   Saturday  2015-01-31     BAYVIEW            NONE\n",
       "7              VANDALISM   Saturday  2015-01-31     BAYVIEW            NONE\n",
       "8               BURGLARY   Saturday  2015-01-31     CENTRAL            NONE\n",
       "9          LARCENY/THEFT   Saturday  2015-01-31     CENTRAL            NONE\n",
       "10         LARCENY/THEFT     Sunday  2015-02-01     MISSION  ARREST, BOOKED\n",
       "11         DRUG/NARCOTIC     Sunday  2015-02-01     MISSION  ARREST, BOOKED\n",
       "12         DRUG/NARCOTIC     Sunday  2015-02-01     MISSION  ARREST, BOOKED\n",
       "13              WARRANTS     Sunday  2015-02-01     MISSION  ARREST, BOOKED\n",
       "14               ROBBERY     Sunday  2015-02-01     MISSION            NONE\n",
       "15         VEHICLE THEFT     Sunday  2015-02-01    NORTHERN            NONE\n",
       "16          NON-CRIMINAL     Sunday  2015-02-01    NORTHERN            NONE\n",
       "17              WARRANTS     Sunday  2015-02-01     BAYVIEW  ARREST, BOOKED\n",
       "18         LARCENY/THEFT     Sunday  2015-02-01        PARK            NONE\n",
       "19        OTHER OFFENSES     Sunday  2015-02-01     BAYVIEW  ARREST, BOOKED\n",
       "20               ROBBERY     Sunday  2015-02-01     CENTRAL  ARREST, BOOKED\n",
       "21               ROBBERY     Sunday  2015-02-01     CENTRAL  ARREST, BOOKED\n",
       "22             VANDALISM     Friday  2016-11-11     MISSION            NONE\n",
       "23               ASSAULT     Sunday  2015-02-01     CENTRAL  ARREST, BOOKED\n",
       "24               ASSAULT     Sunday  2015-02-01     CENTRAL  ARREST, BOOKED\n",
       "25               ROBBERY     Sunday  2015-02-01  TENDERLOIN  ARREST, BOOKED\n",
       "26               ASSAULT     Sunday  2015-02-01  TENDERLOIN  ARREST, BOOKED\n",
       "27           WEAPON LAWS     Sunday  2015-02-01  TENDERLOIN  ARREST, BOOKED\n",
       "28          NON-CRIMINAL     Sunday  2015-02-01     BAYVIEW            NONE\n",
       "29        OTHER OFFENSES     Sunday  2015-02-01  TENDERLOIN  ARREST, BOOKED\n",
       "...                  ...        ...         ...         ...             ...\n",
       "2214984          ASSAULT     Friday  2017-05-12    SOUTHERN            NONE\n",
       "2214985    VEHICLE THEFT     Friday  2017-05-19     TARAVAL            NONE\n",
       "2214986         TRESPASS     Sunday  2017-05-21     TARAVAL  ARREST, BOOKED\n",
       "2214987          ASSAULT   Thursday  2017-05-18    SOUTHERN            NONE\n",
       "2214988          ASSAULT     Monday  2017-05-15  TENDERLOIN            NONE\n",
       "2214989          ASSAULT     Friday  2016-12-30        PARK            NONE\n",
       "2214990     NON-CRIMINAL     Friday  2016-12-30     CENTRAL            NONE\n",
       "2214991    LARCENY/THEFT   Thursday  2016-12-29     CENTRAL            NONE\n",
       "2214992    LARCENY/THEFT     Friday  2016-12-30     CENTRAL            NONE\n",
       "2214993     NON-CRIMINAL     Sunday  2017-01-08        PARK            NONE\n",
       "2214994     NON-CRIMINAL     Friday  2017-01-20     CENTRAL            NONE\n",
       "2214995     NON-CRIMINAL     Friday  2017-02-24    SOUTHERN            NONE\n",
       "2214996        VANDALISM   Saturday  2017-03-18     CENTRAL            NONE\n",
       "2214997     NON-CRIMINAL   Saturday  2017-04-22        PARK            NONE\n",
       "2214998    LARCENY/THEFT     Friday  2017-05-05     CENTRAL            NONE\n",
       "2214999     NON-CRIMINAL     Monday  2017-05-08    SOUTHERN            NONE\n",
       "2215000   OTHER OFFENSES     Friday  2016-12-02    SOUTHERN            NONE\n",
       "2215001         WARRANTS     Sunday  2017-05-14     TARAVAL  ARREST, BOOKED\n",
       "2215002    DRUG/NARCOTIC     Friday  2017-05-12     TARAVAL  ARREST, BOOKED\n",
       "2215003    DRUG/NARCOTIC     Friday  2017-05-12     TARAVAL  ARREST, BOOKED\n",
       "2215004         WARRANTS     Friday  2017-05-12     TARAVAL  ARREST, BOOKED\n",
       "2215005            ARSON     Friday  2017-01-06     MISSION            NONE\n",
       "2215006          ASSAULT     Sunday  2017-01-22     MISSION            NONE\n",
       "2215007          ASSAULT    Tuesday  2017-01-31    SOUTHERN            NONE\n",
       "2215008          ASSAULT     Friday  2017-02-03        PARK            NONE\n",
       "2215009          ASSAULT    Tuesday  2017-02-07  TENDERLOIN            NONE\n",
       "2215010          ASSAULT     Friday  2017-02-10     MISSION            NONE\n",
       "2215011          ASSAULT  Wednesday  2017-03-01    SOUTHERN            NONE\n",
       "2215012    VEHICLE THEFT     Friday  2017-03-03        PARK            NONE\n",
       "2215013          ASSAULT     Monday  2017-01-30  TENDERLOIN            NONE\n",
       "\n",
       "[2215014 rows x 5 columns]>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(dataset.columns[[1,4,5,6,7,8,11,12]], axis=1, inplace=True)\n",
    "dataset.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analizamos las columnas elegidas con el fin de analizar la distancia de la importancia entre ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>2215014</td>\n",
       "      <td>39</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>480448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dayofweek</th>\n",
       "      <td>2215014</td>\n",
       "      <td>12</td>\n",
       "      <td>Friday</td>\n",
       "      <td>336117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>2215014</td>\n",
       "      <td>5618</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district</th>\n",
       "      <td>2215013</td>\n",
       "      <td>34</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>398432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resolution</th>\n",
       "      <td>2215014</td>\n",
       "      <td>27</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1378600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count unique            top     freq\n",
       "category    2215014     39  LARCENY/THEFT   480448\n",
       "dayofweek   2215014     12         Friday   336117\n",
       "date        2215014   5618      Wednesday     1989\n",
       "district    2215013     34       SOUTHERN   398432\n",
       "resolution  2215014     27           NONE  1378600"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización de datos\n",
    "La red neuronal en Python puede tener dificultades para converger antes de la cantidad máxima de iteraciones permitidas si los datos no están normalizados. El Perceptron multicapa es sensible a las incrustaciones de características, por lo que es muy recomendable escalar los datos. Hay que tener en cuenta que debe aplicar la misma escala al conjunto de prueba para obtener resultados significativos. Hay muchos métodos diferentes para la normalización de los datos, utilizaremos el StandardScaler incorporado para la estandarización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>date</th>\n",
       "      <th>district</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  dayofweek        date  district  resolution\n",
       "0         0          0  2015-01-19         0           0\n",
       "1         1          1  2015-02-01         1           0\n",
       "2         2          1  2015-02-01         1           0\n",
       "3         3          1  2015-02-01         1           0\n",
       "4         4          2  2015-01-27         2           0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndataset = dataset\n",
    "categories = { x: ind for ind, x in enumerate(dataset.category.unique()) }\n",
    "ndataset['category'] = ndataset['category'].map(lambda x: categories[x])\n",
    "\n",
    "dayofweek = { x: ind for ind, x in enumerate(dataset.dayofweek.unique()) }\n",
    "ndataset['dayofweek'] = ndataset['dayofweek'].map(lambda x: dayofweek[x])\n",
    "\n",
    "district = { x: ind for ind, x in enumerate(dataset.district.unique()) }\n",
    "ndataset['district'] = ndataset['district'].map(lambda x: district[x])\n",
    "\n",
    "resolution = { x: ind for ind, x in enumerate(dataset.resolution.unique()) }\n",
    "ndataset['resolution'] = ndataset['resolution'].map(lambda x: resolution[x])\n",
    "\n",
    "ndataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalización de la columna de fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>date</th>\n",
       "      <th>district</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.421622e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.422745e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.422745e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.422745e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.422313e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  dayofweek          date  district  resolution\n",
       "0         0          0  1.421622e+09         0           0\n",
       "1         1          1  1.422745e+09         1           0\n",
       "2         2          1  1.422745e+09         1           0\n",
       "3         3          1  1.422745e+09         1           0\n",
       "4         4          2  1.422313e+09         2           0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "def totime(x):\n",
    "    try:\n",
    "        return time.mktime(datetime.datetime.strptime(x, \"%Y-%m-%d\").timetuple())\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "ndataset['date'] = ndataset['date'].map(totime)\n",
    "\n",
    "ndataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          category  dayofweek  district  resolution\n",
       "0               0          0         0           0\n",
       "1               1          1         1           0\n",
       "2               2          1         1           0\n",
       "3               3          1         1           0\n",
       "4               4          2         2           0\n",
       "5               0          1         3           0\n",
       "6               3          3         4           0\n",
       "7               4          3         4           0\n",
       "8               5          3         5           0\n",
       "9               6          3         5           0\n",
       "10              6          1         0           1\n",
       "11              7          1         0           1\n",
       "12              7          1         0           1\n",
       "13              8          1         0           1\n",
       "14              1          1         0           0\n",
       "15              9          1         2           0\n",
       "16              0          1         2           0\n",
       "17              8          1         4           1\n",
       "18              6          1         6           0\n",
       "19             10          1         4           1\n",
       "20              1          1         5           1\n",
       "21              1          1         5           1\n",
       "22              4          4         0           0\n",
       "23              2          1         5           1\n",
       "24              2          1         5           1\n",
       "25              1          1         1           1\n",
       "26              2          1         1           1\n",
       "27             11          1         1           1\n",
       "28              0          1         4           0\n",
       "29             10          1         1           1\n",
       "...           ...        ...       ...         ...\n",
       "2214984         2          4         8           0\n",
       "2214985         9          4         7           0\n",
       "2214986        18          1         7           1\n",
       "2214987         2          6         8           0\n",
       "2214988         2          0         1           0\n",
       "2214989         2          4         6           0\n",
       "2214990         0          4         5           0\n",
       "2214991         6          6         5           0\n",
       "2214992         6          4         5           0\n",
       "2214993         0          1         6           0\n",
       "2214994         0          4         5           0\n",
       "2214995         0          4         8           0\n",
       "2214996         4          3         5           0\n",
       "2214997         0          3         6           0\n",
       "2214998         6          4         5           0\n",
       "2214999         0          0         8           0\n",
       "2215000        10          4         8           0\n",
       "2215001         8          1         7           1\n",
       "2215002         7          4         7           1\n",
       "2215003         7          4         7           1\n",
       "2215004         8          4         7           1\n",
       "2215005        12          4         0           0\n",
       "2215006         2          1         0           0\n",
       "2215007         2          2         8           0\n",
       "2215008         2          4         6           0\n",
       "2215009         2          2         1           0\n",
       "2215010         2          4         0           0\n",
       "2215011         2          5         8           0\n",
       "2215012         9          4         6           0\n",
       "2215013         2          0         1           0\n",
       "\n",
       "[2215014 rows x 4 columns]>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndataset.drop(ndataset.columns[[2]], axis=1, inplace=True)\n",
    "ndataset.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de muestras y entrenamiento.\n",
    "Dividamos nuestros datos en conjuntos de entrenamiento y prueba, esto se hace fácilmente con la función train_test_split de SciKit Learn de model_selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          category  dayofweek  district  resolution\n",
       "0               0          0         0           0\n",
       "1               1          1         1           0\n",
       "2               2          1         1           0\n",
       "3               3          1         1           0\n",
       "4               4          2         2           0\n",
       "5               0          1         3           0\n",
       "6               3          3         4           0\n",
       "7               4          3         4           0\n",
       "8               5          3         5           0\n",
       "9               6          3         5           0\n",
       "10              6          1         0           1\n",
       "11              7          1         0           1\n",
       "12              7          1         0           1\n",
       "13              8          1         0           1\n",
       "14              1          1         0           0\n",
       "15              9          1         2           0\n",
       "16              0          1         2           0\n",
       "17              8          1         4           1\n",
       "18              6          1         6           0\n",
       "19             10          1         4           1\n",
       "20              1          1         5           1\n",
       "21              1          1         5           1\n",
       "22              4          4         0           0\n",
       "23              2          1         5           1\n",
       "24              2          1         5           1\n",
       "25              1          1         1           1\n",
       "26              2          1         1           1\n",
       "27             11          1         1           1\n",
       "28              0          1         4           0\n",
       "29             10          1         1           1\n",
       "...           ...        ...       ...         ...\n",
       "2214984         2          4         8           0\n",
       "2214985         9          4         7           0\n",
       "2214986        18          1         7           1\n",
       "2214987         2          6         8           0\n",
       "2214988         2          0         1           0\n",
       "2214989         2          4         6           0\n",
       "2214990         0          4         5           0\n",
       "2214991         6          6         5           0\n",
       "2214992         6          4         5           0\n",
       "2214993         0          1         6           0\n",
       "2214994         0          4         5           0\n",
       "2214995         0          4         8           0\n",
       "2214996         4          3         5           0\n",
       "2214997         0          3         6           0\n",
       "2214998         6          4         5           0\n",
       "2214999         0          0         8           0\n",
       "2215000        10          4         8           0\n",
       "2215001         8          1         7           1\n",
       "2215002         7          4         7           1\n",
       "2215003         7          4         7           1\n",
       "2215004         8          4         7           1\n",
       "2215005        12          4         0           0\n",
       "2215006         2          1         0           0\n",
       "2215007         2          2         8           0\n",
       "2215008         2          4         6           0\n",
       "2215009         2          2         1           0\n",
       "2215010         2          4         0           0\n",
       "2215011         2          5         8           0\n",
       "2215012         9          4         6           0\n",
       "2215013         2          0         1           0\n",
       "\n",
       "[2215014 rows x 4 columns]>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ndataset.drop('category',axis=1)\n",
    "y = ndataset['category']\n",
    "ndataset.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head(),y.head()\n",
    "x_training, x_test, y_training, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos las transformaciones una vez realizada la normalización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.81277878, -1.96015559, -0.47871692],\n",
       "       [-2.501272  , -1.9435165 , -0.47400278],\n",
       "       [-2.62587471, -1.96015559, -0.47400278],\n",
       "       ..., \n",
       "       [-2.87508013, -1.89359924, -0.47871692],\n",
       "       [-2.81277878, -1.93519696, -0.39386242],\n",
       "       [-2.501272  , -1.91855787, -0.4645745 ]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_training = scaler.transform(x_training)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "x_training\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenador del modelo\n",
    "Ahora es el momento de entrenar a nuestro modelo. SciKit Learn lo hace increíblemente fácil, mediante el uso de objetos estimadores. En este caso, importaremos nuestro estimador (el modelo clasificador de perceptrón multicapa) de la biblioteca neural_network de SciKit-Learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, creamos una instancia del modelo, hay muchos parámetros que puede elegir definir y personalizar aquí, solo definiremos hidden_layer_sizes. \n",
    "\n",
    "* Para este parámetro, se pasa una tupla que consiste en el número de neuronas que se desea en cada capa, donde la enésima entrada de la tupla representa el número de neuronas en la enésima capa del modelo MLP. \n",
    "* Hay muchas maneras de elegir estos números, pero para simplificar, elegiremos 3 capas con el mismo número de neuronas que funciones en nuestro conjunto de datos junto con 100 iteraciones máximas, como ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10, 10, 10), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=100,verbose=10)\n",
    "classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.66331479\n",
      "Iteration 2, loss = 2.62095783\n",
      "Iteration 3, loss = 2.59681230\n",
      "Iteration 4, loss = 2.59505082\n",
      "Iteration 5, loss = 2.59477325\n",
      "Iteration 6, loss = 2.59418773\n",
      "Iteration 7, loss = 2.59380340\n",
      "Iteration 8, loss = 2.59343491\n",
      "Iteration 9, loss = 2.59235191\n",
      "Iteration 10, loss = 2.59068355\n"
     ]
    }
   ],
   "source": [
    "classificador.fit(x_training,y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver el resultado muestra los valores predeterminados de los otros parámetros en el modelo. La idea sería ajustar y definir los parámetros de configuración hasta dar con un modelo ajustado a la información a predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones y Evaluación\n",
    "Ahora que tenemos un modelo, es hora de usarlo para obtener predicciones Podemos hacer esto simplemente con el método predict () fuera de nuestro modelo ajustado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = classificador.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos usar las métricas integradas de SciKit-Learn, como un informe de clasificación y una matriz de confusión para evaluar el rendimiento de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La desventaja de utilizar un modelo Perceptron multicapa es lo difícil que es interpretar el modelo en sí. Los pesos y los sesgos no serán fácilmente interpretables en relación con qué características son importantes para el modelo en sí.\n",
    "\n",
    "Sin embargo, si desea extraer los pesos y sesgos MLP después de entrenar su modelo, use sus atributos públicos coefs_ e intercepts_.\n",
    "\n",
    "coefs_ es una lista de matrices de peso, donde la matriz de ponderación en el índice i representa los pesos entre la capa iy la capa i + 1.\n",
    "\n",
    "intercepts_ es una lista de vectores de sesgo, donde el vector en el índice i representa los valores de sesgo agregados a la capa i + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(classificador.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(classificador.coefs_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(classificador.intercepts_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "Intentaremos jugar con la cantidad de capas y neuronas ocultas y observa cómo afectan los resultados de nuestra red neuronal en Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
